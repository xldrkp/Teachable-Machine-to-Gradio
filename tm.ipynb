{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verwendung von Modellen aus Teachable Machine mit Gradio\n",
    "\n",
    "Der folgende Code wird von TM beim Export des Modells zur Verf端gung gestellt. Er wurde geringf端gig f端r die Hauptfunktion einer Gradio-Anwendung angepasst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitungen\n",
    "\n",
    "Das Beispiel wurde erfolgreich mit folgenden Versionen ausgef端hrt:\n",
    "\n",
    "- Python 3.11.8\n",
    "- Tensorflow 2.12\n",
    "- Keras 2.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras==2.12.0 tensorflow==2.12 pillow gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Originalcode aus TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dies ist der Export aus TM ohne Anpassungen\n",
    "\n",
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"model/keras_model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"model/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "# Replace this with the path to your image\n",
    "image = Image.open(\"data/dogs_test/101.jpg\").convert(\"RGB\")\n",
    "\n",
    "# resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# Predicts the model\n",
    "prediction = model.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "confidence_score = prediction[0][index]\n",
    "\n",
    "# Print prediction and confidence score\n",
    "print(\"Class:\", class_name[2:], end=\"\")\n",
    "print(\"Confidence Score:\", confidence_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio-Anwendung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"model/keras_model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"model/labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "def image_class(image):\n",
    "\n",
    "    # Replace this with the path to your image\n",
    "    # image = Image.open(image).convert(\"RGB\")\n",
    "\n",
    "    # resizing the image to be at least 224x224 and then cropping from the center\n",
    "    size = (224, 224)\n",
    "    image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # turn the image into a numpy array\n",
    "    image_array = np.asarray(image)\n",
    "\n",
    "    # Normalize the image\n",
    "    normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "    # Load the image into the array\n",
    "    data[0] = normalized_image_array\n",
    "\n",
    "    # Predicts the model\n",
    "    prediction = model.predict(data)\n",
    "    index = np.argmax(prediction)\n",
    "    class_name = class_names[index]\n",
    "    confidence_score = prediction[0][index]\n",
    "\n",
    "    return [class_name[2:], (float(confidence_score) * 100)]\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    image_class,\n",
    "    gr.Image(type=\"pil\"),\n",
    "    [\n",
    "        gr.Textbox(label=\"Klasse\"), \n",
    "        gr.Textbox(label=\"Sicherheit der Vorhersage (confidence)\")\n",
    "    ],\n",
    "    flagging_options=[\"incorrect\"],\n",
    "    examples=[\n",
    "        \"data/cats_test/101.jpg\",\n",
    "        \"data/dogs_test/111.jpg\",\n",
    "        \"data/cats_test/102.jpg\",\n",
    "        \"data/dogs_test/112.jpg\",\n",
    "    ],\n",
    "    description=\"\"\"\n",
    "    # Verwendung eines Modells aus Teachable Machine in Gradio\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
